{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import poisson\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import gensim.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    tqdm.pandas()\n",
    "\n",
    "def flatNestedList(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSemesterTermFrequencyMatrixFrom(dataframe, column='Unigrams', min_freq=2, max_freq=500, max_features=100000):\n",
    "    print('Counting term frequency')\n",
    "    df = pd.DataFrame(dataframe[column])\n",
    "    df = df.resample('D',closed='left', label='left').apply(flatNestedList)\n",
    "    cv = CountVectorizer(tokenizer=(lambda x: x), preprocessor=(lambda x: x), min_df=min_freq, max_df=max_freq)\n",
    "    table = cv.fit_transform(df[column])\n",
    "    docterm=pd.DataFrame(table.todense())\n",
    "    docterm.index = df.index\n",
    "    semterm = docterm.resample('2QS',closed='left', label='left').sum()\n",
    "    semterm.columns = cv.get_feature_names()\n",
    "    semterm=semterm.T\n",
    "    columns = semterm.columns.strftime(date_format='%Y-%b')\n",
    "    semterm.columns = np.arange(1,len(semterm.columns)+1).astype(int)\n",
    "    return semterm, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    print('Normalizing')\n",
    "    return df.div(df.sum(axis=0), axis=1)*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrends(df, columns, size, threshold):\n",
    "    print('Creating xls file')\n",
    "    ll=[]\n",
    "    for c in df.columns:\n",
    "        ll.append(np.array(df[df.loc[:,c] < threshold].sort_values(by=[c],ascending=True)[:size].loc[:,c].index))\n",
    "    trends = pd.DataFrame(ll).T\n",
    "    trends.columns = columns[1:]\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    print('Reading data....')\n",
    "    start = time.time()\n",
    "    df = pd.read_pickle(filename)\n",
    "    end = time.time()\n",
    "    print(f'Read finished in {end-start:.2f} seconds.\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Trends\n",
      "Reading data....\n",
      "Read finished in 2.91 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Generating Trends')\n",
    "start = time.time()\n",
    "setup()\n",
    "config = ConfigParser(inline_comment_prefixes=\"#;\", interpolation=ExtendedInterpolation())\n",
    "config.read('config.ini')\n",
    "inputfile = config['Text Cleaning']['tokenized_file']\n",
    "output = config['General']['output_file']\n",
    "writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
    "df= readData(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting term frequency\n",
      "Normalizing\n"
     ]
    }
   ],
   "source": [
    "column = 'Unigrams'\n",
    "semterm, columns = getSemesterTermFrequencyMatrixFrom(df, column)\n",
    "semterm = normalize(semterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52740, 19)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semterm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoisson(df, transform=None):\n",
    "    print ('Calculating poisson percentages')\n",
    "    index = df.index\n",
    "    columns = df.columns\n",
    "    p = pd.DataFrame(poisson.cdf(k=getK(df, transform=transform), mu=df.loc[:,2:len(df.columns)]))\n",
    "    p.columns = columns[1:]\n",
    "    p.index = index\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getK(df, transform=None, past=3):\n",
    "    if transform=='max':\n",
    "        table = np.zeros(shape=df.shape)\n",
    "        for i, (index, row) in tqdm(enumerate(df.iterrows())):\n",
    "            for j in range(len(df.columns)-1): \n",
    "                table[i,j] = max(row[:j+1])\n",
    "    if transform=='mean':\n",
    "        table = np.zeros(shape=df.shape)\n",
    "        for i, (index, row) in tqdm(enumerate(df.iterrows())):\n",
    "            for j in range(len(df.columns)-1):\n",
    "                bound = max(0,j-past)\n",
    "                table[i,j] = row[bound:j+1].mean()\n",
    "        df = pd.DataFrame(table, index = df.index, columns=df.columns)\n",
    "        \n",
    "    return df.loc[:,1:len(df.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating poisson percentages\n"
     ]
    }
   ],
   "source": [
    "p = getPoisson(semterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Unigrams', 'Bigrams']:\n",
    "    semterm, columns = getSemesterTermFrequencyMatrixFrom(df, column)\n",
    "    semterm = normalize(semterm)\n",
    "    p = getPoisson(semterm)\n",
    "    trends = generateTrends(p, columns, 1000, 0.05)\n",
    "    trends.to_excel(writer, sheet_name=column)\n",
    "writer.save()\n",
    "end = time.time()\n",
    "print(f'Excel file generated in {end-start:.2f} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
