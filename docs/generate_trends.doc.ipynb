{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import poisson\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import gensim.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup()\n",
    "config = ConfigParser(inline_comment_prefixes=\"#;\", interpolation=ExtendedInterpolation())\n",
    "config.read('../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = config['Text Cleaning']['tokenized_file']\n",
    "output = config['General']['output_file']\n",
    "min_freq = config['General']['min_freq']\n",
    "max_freq = config['General']['max_freq']\n",
    "dict_size = config['General']['dict_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/tokenized.data', './data/trends.xlsx')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputfile, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = '../data/tokenized.data'\n",
    "output = '../data/trends.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    print('Reading data....')\n",
    "    start = time.time()\n",
    "    df = pd.read_pickle(filename)\n",
    "    end = time.time()\n",
    "    print(f'Read finished in {end-start:.2f} seconds.\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data....\n",
      "Read finished in 3.05 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
    "df= readData(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>From</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Unigrams</th>\n",
       "      <th>Bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>65285</td>\n",
       "      <td>@SAI</td>\n",
       "      <td>top objectively biggest tech stories of</td>\n",
       "      <td>[objectively, tech, stories]</td>\n",
       "      <td>[objectively tech, tech stories]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>195166</td>\n",
       "      <td>@guardiantech</td>\n",
       "      <td>silicon valley campaign seeks startup visa for...</td>\n",
       "      <td>[silicon, campaign, seeks, startup, visa, fore...</td>\n",
       "      <td>[silicon campaign, campaign seeks, seeks start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502284</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>: my fifth annual list of the tech products i ...</td>\n",
       "      <td>[fifth, list, tech, products, love, use]</td>\n",
       "      <td>[fifth list, list tech, tech products, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502285</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>namebench: google % project to find the fastes...</td>\n",
       "      <td>[namebench, project, find, fastest, dns, server]</td>\n",
       "      <td>[namebench project, project find, find fastest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502286</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>six new years resolutions for apple and the ip...</td>\n",
       "      <td>[six, resolutions]</td>\n",
       "      <td>[six resolutions]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index           From  \\\n",
       "Date                                \n",
       "2010-01-01   65285           @SAI   \n",
       "2010-01-01  195166  @guardiantech   \n",
       "2010-01-01  502284    @TechCrunch   \n",
       "2010-01-01  502285    @TechCrunch   \n",
       "2010-01-01  502286    @TechCrunch   \n",
       "\n",
       "                                                        Tweet  \\\n",
       "Date                                                            \n",
       "2010-01-01           top objectively biggest tech stories of    \n",
       "2010-01-01  silicon valley campaign seeks startup visa for...   \n",
       "2010-01-01  : my fifth annual list of the tech products i ...   \n",
       "2010-01-01  namebench: google % project to find the fastes...   \n",
       "2010-01-01  six new years resolutions for apple and the ip...   \n",
       "\n",
       "                                                     Unigrams  \\\n",
       "Date                                                            \n",
       "2010-01-01                       [objectively, tech, stories]   \n",
       "2010-01-01  [silicon, campaign, seeks, startup, visa, fore...   \n",
       "2010-01-01           [fifth, list, tech, products, love, use]   \n",
       "2010-01-01   [namebench, project, find, fastest, dns, server]   \n",
       "2010-01-01                                 [six, resolutions]   \n",
       "\n",
       "                                                      Bigrams  \n",
       "Date                                                           \n",
       "2010-01-01                   [objectively tech, tech stories]  \n",
       "2010-01-01  [silicon campaign, campaign seeks, seeks start...  \n",
       "2010-01-01  [fifth list, list tech, tech products, product...  \n",
       "2010-01-01  [namebench project, project find, find fastest...  \n",
       "2010-01-01                                  [six resolutions]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>index</th>\n",
       "      <th>From</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Unigrams</th>\n",
       "      <th>Bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>65285</td>\n",
       "      <td>@SAI</td>\n",
       "      <td>top objectively biggest tech stories of</td>\n",
       "      <td>[objectively, tech, stories]</td>\n",
       "      <td>[objectively tech, tech stories]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>195166</td>\n",
       "      <td>@guardiantech</td>\n",
       "      <td>silicon valley campaign seeks startup visa for...</td>\n",
       "      <td>[silicon, campaign, seeks, startup, visa, fore...</td>\n",
       "      <td>[silicon campaign, campaign seeks, seeks start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>502284</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>: my fifth annual list of the tech products i ...</td>\n",
       "      <td>[fifth, list, tech, products, love, use]</td>\n",
       "      <td>[fifth list, list tech, tech products, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>502285</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>namebench: google % project to find the fastes...</td>\n",
       "      <td>[namebench, project, find, fastest, dns, server]</td>\n",
       "      <td>[namebench project, project find, find fastest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>502286</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>six new years resolutions for apple and the ip...</td>\n",
       "      <td>[six, resolutions]</td>\n",
       "      <td>[six resolutions]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   index           From  \\\n",
       "0 2010-01-01   65285           @SAI   \n",
       "1 2010-01-01  195166  @guardiantech   \n",
       "2 2010-01-01  502284    @TechCrunch   \n",
       "3 2010-01-01  502285    @TechCrunch   \n",
       "4 2010-01-01  502286    @TechCrunch   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0           top objectively biggest tech stories of    \n",
       "1  silicon valley campaign seeks startup visa for...   \n",
       "2  : my fifth annual list of the tech products i ...   \n",
       "3  namebench: google % project to find the fastes...   \n",
       "4  six new years resolutions for apple and the ip...   \n",
       "\n",
       "                                            Unigrams  \\\n",
       "0                       [objectively, tech, stories]   \n",
       "1  [silicon, campaign, seeks, startup, visa, fore...   \n",
       "2           [fifth, list, tech, products, love, use]   \n",
       "3   [namebench, project, find, fastest, dns, server]   \n",
       "4                                 [six, resolutions]   \n",
       "\n",
       "                                             Bigrams  \n",
       "0                   [objectively tech, tech stories]  \n",
       "1  [silicon campaign, campaign seeks, seeks start...  \n",
       "2  [fifth list, list tech, tech products, product...  \n",
       "3  [namebench project, project find, find fastest...  \n",
       "4                                  [six resolutions]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['From', 'Date'])['Unigrams'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['From', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['temp']=g['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['temp']=g['From']+'---'+g['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_index('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = g.groupby('temp')['Unigrams'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = '@BBCTech---2010-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.DataFrame(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['From']=h.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['Date']= h['From'].apply(lambda x: x.split('---')[1])\n",
    "h['From']= h['From'].apply(lambda x: x.split('---')[0])\n",
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['Date']=pd.to_datetime(h['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.set_index('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatNestedList(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['Unigrams']=h['Unigrams'].apply(flatNestedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.resample('2QS',closed='left', label='left').apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.apply(flatNestedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=(lambda x: x), preprocessor=(lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = cv.fit_transform(f['Unigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromterm = pd.DataFrame(table.todense())\n",
    "fromterm.index = f.index\n",
    "fromterm.columns = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromterm = fromterm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSemesterTermFrequencyMatrixFrom(dataframe, column='Unigrams', min_freq=2, max_freq=500, max_features=100000):\n",
    "    print('Counting term frequency')\n",
    "    df = pd.DataFrame(dataframe[column])\n",
    "    df = df.resample('D',closed='left', label='left').apply(flatNestedList)\n",
    "    cv = CountVectorizer(tokenizer=(lambda x: x), preprocessor=(lambda x: x), min_df=min_freq, max_df=max_freq)\n",
    "    table = cv.fit_transform(df[column])\n",
    "    docterm=pd.DataFrame(table.todense())\n",
    "    docterm.index = df.index\n",
    "    semterm = docterm.resample('2QS',closed='left', label='left').sum()\n",
    "    semterm.columns = cv.get_feature_names()\n",
    "    semterm=semterm.T\n",
    "    columns = semterm.columns.strftime(date_format='%Y-%b')\n",
    "    semterm.columns = np.arange(1,len(semterm.columns)+1).astype(int)\n",
    "    return semterm, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    print('Normalizing')\n",
    "    return df.div(df.sum(axis=0), axis=1)*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getK(df, transform=None, past=3):\n",
    "    if transform == 'max':\n",
    "        table = np.zeros(shape=df.shape)\n",
    "        for i, (index, row) in tqdm(enumerate(df.iterrows())):\n",
    "            for j in range(len(df.columns)-1):\n",
    "                table[i, j] = max(row[:j+1])\n",
    "    if transform == 'mean':\n",
    "        table = np.zeros(shape=df.shape)\n",
    "        for i, (index, row) in tqdm(enumerate(df.iterrows())):\n",
    "            for j in range(len(df.columns)-1):\n",
    "                bound = max(0, j-past)\n",
    "                table[i, j] = row[bound:j+1].mean()\n",
    "        df = pd.DataFrame(table, index=df.index, columns=df.columns)\n",
    "    return df.loc[:, 1:len(df.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoisson(df, transform=None):\n",
    "    print('Calculating poisson percentages')\n",
    "    index = df.index\n",
    "    columns = df.columns\n",
    "    p = pd.DataFrame(poisson.cdf(k=getK(df, transform=transform), mu=df.loc[:, 2:len(df.columns)]))\n",
    "    p.columns = columns[1:]\n",
    "    p.index = index\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrends(df, columns, size, threshold):\n",
    "    print('Creating xls file')\n",
    "    ll=[]\n",
    "    for c in df.columns:\n",
    "        ll.append(np.array(df[df.loc[:,c] < threshold].sort_values(by=[c],ascending=True)[:size].loc[:,c].index))\n",
    "    trends = pd.DataFrame(ll).T\n",
    "    trends.columns = columns[1:]\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for column in ['Unigrams', 'Bigrams']:\n",
    "    semterm, columns = getSemesterTermFrequencyMatrixFrom(df, column)\n",
    "    semterm = normalize(semterm)\n",
    "    p = getPoisson(semterm)\n",
    "    trends = generateTrends(p, columns, 1000, 0.05)\n",
    "    trends.to_excel(writer, sheet_name=column)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
