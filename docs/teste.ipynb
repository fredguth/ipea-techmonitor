{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import poisson\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import gensim.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    tqdm.pandas()\n",
    "\n",
    "def flatNestedList(list_of_lists):\n",
    "    return [val for sublist in list_of_lists for val in sublist]\n",
    "\n",
    "def getSemesterTermFrequencyMatrixFrom(dataframe, column='Unigrams', min_freq=2, max_freq=500, max_features=100000):\n",
    "    print('Counting term frequency')\n",
    "    df = pd.DataFrame(dataframe[column])\n",
    "    df = df.resample('D',closed='left', label='left').apply(flatNestedList)\n",
    "    cv = CountVectorizer(tokenizer=(lambda x: x), preprocessor=(lambda x: x), min_df=min_freq, max_df=max_freq)\n",
    "    table = cv.fit_transform(df[column])\n",
    "    docterm=pd.DataFrame(table.todense())\n",
    "    docterm.index = df.index\n",
    "    semterm = docterm.resample('2QS',closed='left', label='left').sum()\n",
    "    semterm.columns = cv.get_feature_names()\n",
    "    semterm=semterm.T\n",
    "    columns = semterm.columns.strftime(date_format='%Y-%b')\n",
    "    semterm.columns = np.arange(1,len(semterm.columns)+1).astype(int)\n",
    "    return semterm, columns\n",
    "\n",
    "def normalize(df):\n",
    "    print('Normalizing')\n",
    "    return df.div(df.sum(axis=0), axis=1)*100000\n",
    "\n",
    "def getPoisson(df):\n",
    "    print ('Calculating poisson percentages')\n",
    "    index = df.index\n",
    "    columns = df.columns\n",
    "    p = pd.DataFrame(poisson.cdf(k=df.loc[:,2:len(df.columns)],mu=df.loc[:,1:len(df.columns)-1]))\n",
    "    p.columns = columns[1:]\n",
    "    p.index = index\n",
    "    return p\n",
    "\n",
    "\n",
    "def generateTrends(df, columns, size, threshold):\n",
    "    print('Creating xls file')\n",
    "    ll=[]\n",
    "    for c in df.columns:\n",
    "        ll.append(np.array(df[df.loc[:,c] < threshold].sort_values(by=[c],ascending=True)[:size].loc[:,c].index))\n",
    "    trends = pd.DataFrame(ll).T\n",
    "    trends.columns = columns[1:]\n",
    "    return trends\n",
    "\n",
    "def readData(filename):\n",
    "    print('Reading data....')\n",
    "    start = time.time()\n",
    "    df = pd.read_pickle(filename)\n",
    "    end = time.time()\n",
    "    print(f'Read finished in {end-start:.2f} seconds.\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Trends\n"
     ]
    }
   ],
   "source": [
    "print('Generating Trends')\n",
    "start = time.time()\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigParser(inline_comment_prefixes=\"#;\", interpolation=ExtendedInterpolation())\n",
    "config.read('../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = config['Text Cleaning']['tokenized_file']\n",
    "output = config['General']['output_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/tokenized.data', './data/trends.xls')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputfile, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(output, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = '../data/tokenized.data'\n",
    "output= '../data/trends.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data....\n",
      "Read finished in 2.99 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= readData(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>From</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Unigrams</th>\n",
       "      <th>Bigrams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>65285</td>\n",
       "      <td>@SAI</td>\n",
       "      <td>top objectively biggest tech stories of</td>\n",
       "      <td>[objectively, tech, stories]</td>\n",
       "      <td>[objectively tech, tech stories]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>195166</td>\n",
       "      <td>@guardiantech</td>\n",
       "      <td>silicon valley campaign seeks startup visa for...</td>\n",
       "      <td>[silicon, campaign, seeks, startup, visa, fore...</td>\n",
       "      <td>[silicon campaign, campaign seeks, seeks start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502284</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>: my fifth annual list of the tech products i ...</td>\n",
       "      <td>[fifth, list, tech, products, love, use]</td>\n",
       "      <td>[fifth list, list tech, tech products, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502285</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>namebench: google % project to find the fastes...</td>\n",
       "      <td>[namebench, project, find, fastest, dns, server]</td>\n",
       "      <td>[namebench project, project find, find fastest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>502286</td>\n",
       "      <td>@TechCrunch</td>\n",
       "      <td>six new years resolutions for apple and the ip...</td>\n",
       "      <td>[six, resolutions]</td>\n",
       "      <td>[six resolutions]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index           From  \\\n",
       "Date                                \n",
       "2010-01-01   65285           @SAI   \n",
       "2010-01-01  195166  @guardiantech   \n",
       "2010-01-01  502284    @TechCrunch   \n",
       "2010-01-01  502285    @TechCrunch   \n",
       "2010-01-01  502286    @TechCrunch   \n",
       "\n",
       "                                                        Tweet  \\\n",
       "Date                                                            \n",
       "2010-01-01           top objectively biggest tech stories of    \n",
       "2010-01-01  silicon valley campaign seeks startup visa for...   \n",
       "2010-01-01  : my fifth annual list of the tech products i ...   \n",
       "2010-01-01  namebench: google % project to find the fastes...   \n",
       "2010-01-01  six new years resolutions for apple and the ip...   \n",
       "\n",
       "                                                     Unigrams  \\\n",
       "Date                                                            \n",
       "2010-01-01                       [objectively, tech, stories]   \n",
       "2010-01-01  [silicon, campaign, seeks, startup, visa, fore...   \n",
       "2010-01-01           [fifth, list, tech, products, love, use]   \n",
       "2010-01-01   [namebench, project, find, fastest, dns, server]   \n",
       "2010-01-01                                 [six, resolutions]   \n",
       "\n",
       "                                                      Bigrams  \n",
       "Date                                                           \n",
       "2010-01-01                   [objectively tech, tech stories]  \n",
       "2010-01-01  [silicon campaign, campaign seeks, seeks start...  \n",
       "2010-01-01  [fifth list, list tech, tech products, product...  \n",
       "2010-01-01  [namebench project, project find, find fastest...  \n",
       "2010-01-01                                  [six resolutions]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting term frequency\n",
      "Normalizing\n",
      "Calculating poisson percentages\n",
      "Creating xls file\n",
      "Counting term frequency\n",
      "Normalizing\n",
      "Calculating poisson percentages\n",
      "Creating xls file\n",
      "Excel file generated in 173.81 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in ['Unigrams', 'Bigrams']:\n",
    "    semterm, columns = getSemesterTermFrequencyMatrixFrom(df, column)\n",
    "    semterm = normalize(semterm)\n",
    "    p = getPoisson(semterm)\n",
    "    trends = generateTrends(p, columns, 1000, 0.05)\n",
    "    trends.to_excel(writer, sheet_name=column)\n",
    "end = time.time()\n",
    "print(f'Excel file generated in {end-start:.2f} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
