{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from gensim.models import LdaModel, LsiModel, HdpModel, LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import pyLDAvis.gensim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser(inline_comment_prefixes=\"#;\", interpolation=ExtendedInterpolation())\n",
    "config.read('config.ini')\n",
    "xlsfile = config['General']['output_file'] # output of generate trends is input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    print('Reading data....')\n",
    "    start = time.time()\n",
    "    df = pd.read_pickle(filename)\n",
    "    end = time.time()\n",
    "    print(f'Read finished in {end-start:.2f} seconds.\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas sheets de unigramas e bigramas, os tÃ³picos estÃ£o na Ãºltima coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data....\n",
      "Read finished in 2.90 seconds.\n",
      "\n",
      "Generating models....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "518145it [00:02, 216346.73it/s]\n",
      "/usr/local/Cellar/jupyter/1.0.0_5/libexec/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated model ./models/lda_Unigrams_30_d01-01-2010d_d30-06-2019d_12 in 77.49 seconds. \n",
      "\n",
      "Generated in 81.61 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputfile = config['Text Cleaning']['tokenized_file']\n",
    "df = readData(inputfile)\n",
    "print('Generating models....')\n",
    "start = time.time()\n",
    "# for gram in [0,1]:\n",
    "for gram in [0]:\n",
    "    column =  pd.read_excel(xlsfile, sheet_name=gram).iloc[:,-1]    \n",
    "#     for size in [30, 100, 500]:\n",
    "    for size in [30]:\n",
    "        trends = (column[~column.isnull()])[:size].to_list()\n",
    "        \n",
    "#         for mask in [('01-01-2010', '30-06-2019'), ('01-01-2019', '30-06-2019')]:\n",
    "        for mask in [('01-01-2010', '30-06-2019')]:\n",
    "            start_date, end_date = mask\n",
    "            data = df.reset_index()\n",
    "            data['Date'] = pd.to_datetime(data['Date'])\n",
    "            mask = (data['Date']>=start_date) & (data['Date']<=end_date)\n",
    "            column_name=['Unigrams', 'Bigrams'][gram]\n",
    "            data = data[mask][column_name]\n",
    "            idxs = []\n",
    "            #filtering rows with trend in trends\n",
    "            for idx, row in tqdm(enumerate(data.to_list())):\n",
    "                for trend in row:\n",
    "                    if trend in trends:\n",
    "                        idxs.append(idx)\n",
    "            texts = df.ix[idxs].reset_index()[column_name]\n",
    "            dictionary = Dictionary(texts)\n",
    "            corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#             for num_topics in [6, 12, 24]:\n",
    "            for num_topics in [12]:\n",
    "                startmodel = time.time()\n",
    "                ldamodel = LdaModel(corpus=corpus,\n",
    "                    num_topics=num_topics, \n",
    "                    id2word=dictionary, \n",
    "                    random_state=42, \n",
    "                    update_every=1, \n",
    "                    chunksize=100, \n",
    "                    passes=10, \n",
    "                    alpha='auto', \n",
    "                    per_word_topics=True)\n",
    "                endmodel = time.time()\n",
    "                filename = f'./models/lda_{column_name}_{size}_d{start_date}d_d{end_date}d_{num_topics}'\n",
    "                with open(filename+'.model', 'wb') as handle:\n",
    "                    pickle.dump(ldamodel, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                with open(filename+'.corpus', 'wb') as handle:\n",
    "                    pickle.dump(corpus, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                with open(filename+'.dict', 'wb') as handle:\n",
    "                    pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                print(f'Generated model {filename} in {endmodel-startmodel:.2f} seconds. \\n')\n",
    "end = time.time()\n",
    "print(f'Generated in {end-start:.2f} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "end = time.time()\n",
    "print(f'Prepared visualization in {end-start:.2f} seconds.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.update({'MALLET_HOME':\"/usr/local/opt/mallet-2.0.8/bin/mallet\"})# update this path accordingly\n",
    "\n",
    "mallet_path = \"/usr/local/opt/mallet-2.0.8/bin/mallet\" # update this path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamallet = LdaMallet(mallet_path, \n",
    "                        corpus=corpus, \n",
    "                        num_topics=12, \n",
    "                        id2word=dictionary,   \n",
    "                        workers=4)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit3d1e6591a0a94d29987f45f3400b13c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
